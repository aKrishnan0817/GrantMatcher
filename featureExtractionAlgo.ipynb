{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "client = openai.OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature-based Similarity Score: 0.9839916686711934\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "# Initialize OpenAI client (using environment variable for API key)\n",
    "\n",
    "# Define the evaluation categories\n",
    "CATEGORIES = [\n",
    "    \"Thematic Alignment\",\n",
    "    \"Innovation\",\n",
    "    \"Feasibility\",\n",
    "    \"Community/Geographic Impact\",\n",
    "    \"Technical/Research Depth\"\n",
    "]\n",
    "\n",
    "def extract_features(description: str) -> dict:\n",
    "    \"\"\"\n",
    "    Use the ChatGPT API to extract a feature vector from a description.\n",
    "    The API is prompted to rate the description on predefined categories.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert in evaluating grant and project descriptions. \n",
    "    Please analyze the following text and provide a rating from 0 to 1 for each of the following categories: {\", \".join(CATEGORIES)}.\n",
    "    Output your answer as a JSON object where keys are the category names and values are the ratings.\n",
    "    \n",
    "    Text:\n",
    "    {description}\n",
    "    \"\"\"\n",
    "    completion = client.chat.completions.create(  # Updated API call\n",
    "        model=\"gpt-4\",  # or gpt-3.5-turbo\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.3,\n",
    "    )\n",
    "\n",
    "    content = completion.choices[0].message.content  # Access content correctly\n",
    "    try:\n",
    "        features = json.loads(content)\n",
    "    except json.JSONDecodeError:\n",
    "        raise ValueError(f\"Could not parse JSON from LLM output: {content}\") # Better error message\n",
    "    return features\n",
    "\n",
    "def vector_from_features(features: dict) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Convert the features dictionary into a NumPy vector.\n",
    "    \"\"\"\n",
    "    return np.array([features[cat] for cat in CATEGORIES], dtype=float)\n",
    "\n",
    "def cosine_similarity(vec1: np.ndarray, vec2: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Compute the cosine similarity between two vectors.\n",
    "    \"\"\"\n",
    "    return np.dot(vec1, vec2) / (norm(vec1) * norm(vec2) + 1e-8)\n",
    "\n",
    "# Example grant and project texts\n",
    "grant_description = \"\"\"\n",
    "This grant supports innovative research in renewable energy and emphasizes sustainable, community-driven solutions.\n",
    "Applicants should demonstrate a strong alignment with environmental themes and present rigorous, innovative methodologies.\n",
    "\"\"\"\n",
    "\n",
    "project_proposal = \"\"\"\n",
    "researching and actively deriving methodologies for interpreting neural networks, which are commonly considered “black boxes.” As AI increasingly touches upon all aspects of our lives, it becomes ever more important to understand what informs model predictions. Using linear algebra and function analysis techniques, I’ve developed a mathematical framework for a system that can take a neural network’s output and identify the set of inputs occupying an N-dimensional space that result in that output. I’ve successfully implemented this system for small networks and confirmed my hypothesis. Now, I am working on applying it to larger and different network architectures. I believe analyzing this space will provide powerful insights into the behavior of neural networks.\n",
    "\"\"\"\n",
    "\n",
    "# Extract feature vectors using the LLM\n",
    "grant_features = extract_features(grant_description)\n",
    "project_features = extract_features(project_proposal)\n",
    "\n",
    "grant_vector = vector_from_features(grant_features)\n",
    "project_vector = vector_from_features(project_features)\n",
    "\n",
    "# Compute the similarity between the grant and the project\n",
    "sim_score = cosine_similarity(grant_vector, project_vector)\n",
    "print(\"Feature-based Similarity Score:\", sim_score)\n",
    "\n",
    "# ... (rest of your code for large datasets would go here)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": ".env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
